# ASSERT TOOLS

This repository contains tools for evaluating the quality of summaries generated by LLMs.

## Installation

```bash
pip install assert-tools
```

## Usage

```python
# test_assert.py
from assert_tools.core import evaluate_summary

# Example text from an article
full_text = """
Artificial intelligence is rapidly transforming the world economy. Companies 
are investing billions in AI research and development, leading to breakthroughs 
in automation, data analysis, and decision-making processes. While this 
technology offers immense benefits, it also raises concerns about job 
displacement and ethical considerations.
"""

# Example summary
summary = """
AI is transforming the economy through major investments, bringing advances in 
automation and analytics while raising job and ethical concerns.
"""

# Get evaluation metrics
metrics = evaluate_summary(full_text, summary)

# Print results
print("\nOriginal Text:")
print(full_text)
print("\nSummary:")
print(summary)
print("\nEvaluation Metrics:")
for metric, score in metrics.items():
    print(f"{metric}: {score:.4f}")

```

